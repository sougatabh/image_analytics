{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat vs Dog\n",
    "Objective of the model is to identify Cat or Dog. \n",
    "Downlaoded the sample Data from Kaggle (https://www.kaggle.com/c/dogs-vs-cats/data). Not uploading the data as part of source code as its size is more.\n",
    "Used GCP instance for analytsis. GPUs(1 x NVIDIA Tesla T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##limit TensorFlow GPU memory fraction: For example, the following will make sure TensorFlow uses <= 90% of your RAM:\n",
    "## Also make sure you delete rm -rf ~/.nv\n",
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process\n",
    "We will move Images under cat and dog folder respectively, from their names, cat images are named as cat.XXXX.jpg and dog as dog.XXXX.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(prefix,start_idx,end_idx,base_dir,source_dir,target_dir):\n",
    "    images_paths = [os.path.join(base_dir,source_dir,prefix+'.'+str(i)+'.jpg') for i in range(start_idx,end_idx)]\n",
    "    dest_dir = os.path.join(base_dir,'model_input',target_dir,prefix)\n",
    "    print(dest_dir)\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    for image_path in images_paths:\n",
    "        shutil.copy(image_path,dest_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'data/cat_vs_dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env.\n",
    "With the above GPU also I was getting OOM error, hence reduced the sample size as below\n",
    "training set 5000 of each category and test set 1000 of each\n",
    "with 5000 each set we saw\n",
    "0] Tesla T4         | 75'C,   0 % | 14787 / 15079 MB | python/31063(14769M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cat_vs_dog/model_input/train/dog\n",
      "data/cat_vs_dog/model_input/train/cat\n"
     ]
    }
   ],
   "source": [
    "## We would copy only 5000 files of each category for training and 1000 of each for testing.\n",
    "copy_files('dog',0,5000,IMAGE_DIR,'train','train')\n",
    "copy_files('cat',0,5000,IMAGE_DIR,'train','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cat_vs_dog/model_input/test/dog\n",
      "data/cat_vs_dog/model_input/test/cat\n"
     ]
    }
   ],
   "source": [
    "copy_files('dog',5000,6000,IMAGE_DIR,'train','test')\n",
    "copy_files('cat',5000,6000,IMAGE_DIR,'train','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants Declarations\n",
    "IMAGE_HEIGHT,IMAGE_WIDTH = 150,150\n",
    "INPUT_SHAPE=(IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "### Model parameter\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 10\n",
    "NO_CLASSES = 2\n",
    "TRAINING_SIZE = 5000\n",
    "TEST_SIZE = 1000\n",
    "VALIDATION_SIZE = 1000\n",
    "EPOCH_STEPS = TRAINING_SIZE//BATCH_SIZE\n",
    "TEST_STEP = TEST_SIZE//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELING_INPUT_DIR = os.path.join(IMAGE_DIR,'model_input')\n",
    "train_dir = os.path.join(MODELING_INPUT_DIR,'train')\n",
    "test_dir = os.path.join(MODELING_INPUT_DIR,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "We would use generator as Images are more, Here we would use keras Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_directory(train_dir,batch_size=BATCH_SIZE,target_size=(IMAGE_WIDTH,IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_images = test_generator.flow_from_directory(test_dir,batch_size=BATCH_SIZE,target_size=(IMAGE_WIDTH,IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN Model\n",
    "Let us build a simple cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape,no_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3), activation = 'relu', input_shape = input_shape))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # Add another:\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    # Add a softmax layer with 10 output units:\n",
    "    model.add(Dense(no_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/analytics/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cnn_model = build_cnn_model(INPUT_SHAPE,NO_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,347,330\n",
      "Trainable params: 5,347,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let us train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/analytics/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 0.7464 - accuracy: 0.5218 - val_loss: 0.6981 - val_accuracy: 0.5402\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 0.6823 - accuracy: 0.5590 - val_loss: 0.6618 - val_accuracy: 0.6473\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 0.6234 - accuracy: 0.6649 - val_loss: 0.5953 - val_accuracy: 0.6415\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 11s 285ms/step - loss: 0.6009 - accuracy: 0.6739 - val_loss: 0.4911 - val_accuracy: 0.7171\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 0.5530 - accuracy: 0.7195 - val_loss: 0.5091 - val_accuracy: 0.7087\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 12s 306ms/step - loss: 0.5327 - accuracy: 0.7334 - val_loss: 0.4474 - val_accuracy: 0.7355\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 0.4847 - accuracy: 0.7633 - val_loss: 0.4910 - val_accuracy: 0.7358\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 0.4864 - accuracy: 0.7672 - val_loss: 0.5575 - val_accuracy: 0.7338\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 0.4463 - accuracy: 0.7873 - val_loss: 0.5482 - val_accuracy: 0.7394\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 0.4242 - accuracy: 0.8043 - val_loss: 0.5226 - val_accuracy: 0.7630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8b3c609b00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit_generator(train_images,steps_per_epoch=EPOCH_STEPS,epochs=EPOCH,validation_data=test_images,validation_steps=TEST_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
