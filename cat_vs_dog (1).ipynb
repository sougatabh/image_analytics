{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat vs Dog\n",
    "Objective of the model is to identify Cat or Dog. \n",
    "Downlaoded the sample Data from Kaggle (https://www.kaggle.com/c/dogs-vs-cats/data). Not uploading the data as part of source code as its size is more.\n",
    "Used GCP instance for analytsis. GPUs(1 x NVIDIA Tesla T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/analytics/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##limit TensorFlow GPU memory fraction: For example, the following will make sure TensorFlow uses <= 90% of your RAM:\n",
    "## Also make sure you delete rm -rf ~/.nv\n",
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process\n",
    "We will move Images under cat and dog folder respectively, from their names, cat images are named as cat.XXXX.jpg and dog as dog.XXXX.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(prefix,start_idx,end_idx,base_dir,source_dir,target_dir):\n",
    "    images_paths = [os.path.join(base_dir,source_dir,prefix+'.'+str(i)+'.jpg') for i in range(start_idx,end_idx)]\n",
    "    dest_dir = os.path.join(base_dir,'model_input',target_dir,prefix)\n",
    "    print(dest_dir)\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    for image_path in images_paths:\n",
    "        shutil.copy(image_path,dest_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'data/cat_vs_dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env.\n",
    "With the above GPU also I was getting OOM error, hence reduced the sample size as below\n",
    "training set 5000 of each category and test set 1000 of each\n",
    "with 5000 each set we saw\n",
    "0] Tesla T4         | 75'C,   0 % | 14787 / 15079 MB | python/31063(14769M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cat_vs_dog/model_input/train/dog\n",
      "data/cat_vs_dog/model_input/train/cat\n"
     ]
    }
   ],
   "source": [
    "## We would copy only 5000 files of each category for training and 1000 of each for testing.\n",
    "copy_files('dog',0,5000,IMAGE_DIR,'train','train')\n",
    "copy_files('cat',0,5000,IMAGE_DIR,'train','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cat_vs_dog/model_input/test/dog\n",
      "data/cat_vs_dog/model_input/test/cat\n"
     ]
    }
   ],
   "source": [
    "copy_files('dog',5000,6000,IMAGE_DIR,'train','test')\n",
    "copy_files('cat',5000,6000,IMAGE_DIR,'train','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants Declarations\n",
    "IMAGE_HEIGHT,IMAGE_WIDTH = 150,150\n",
    "INPUT_SHAPE=(IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "### Model parameter\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 10\n",
    "NO_CLASSES = 2\n",
    "TRAINING_SIZE = 5000\n",
    "TEST_SIZE = 1000\n",
    "VALIDATION_SIZE = 1000\n",
    "EPOCH_STEPS = TRAINING_SIZE//BATCH_SIZE\n",
    "TEST_STEP = TEST_SIZE//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELING_INPUT_DIR = os.path.join(IMAGE_DIR,'model_input')\n",
    "train_dir = os.path.join(MODELING_INPUT_DIR,'train')\n",
    "test_dir = os.path.join(MODELING_INPUT_DIR,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "We would use generator as Images are more, Here we would use keras Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_directory(train_dir,batch_size=BATCH_SIZE,target_size=(IMAGE_WIDTH,IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_images = test_generator.flow_from_directory(test_dir,batch_size=BATCH_SIZE,target_size=(IMAGE_WIDTH,IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN Model\n",
    "Let us build a simple cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape,no_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3), activation = 'relu', input_shape = input_shape))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # Add another:\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Flatten())\n",
    "    ##Add abother\n",
    "    model.add(Dense(units=1024, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    # Add a sigmoid layer\n",
    "    model.add(Dense(no_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model(INPUT_SHAPE,NO_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 165888)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              169870336 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 169,948,034\n",
      "Trainable params: 169,948,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let us train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 15s 389ms/step - loss: 1.4340 - accuracy: 0.5502 - val_loss: 0.6314 - val_accuracy: 0.6964\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 0.6374 - accuracy: 0.6461 - val_loss: 0.6005 - val_accuracy: 0.6825\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 0.6093 - accuracy: 0.6829 - val_loss: 0.6288 - val_accuracy: 0.6651\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 0.6123 - accuracy: 0.6715 - val_loss: 0.6087 - val_accuracy: 0.7026\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 0.5552 - accuracy: 0.7270 - val_loss: 0.5588 - val_accuracy: 0.7276\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 0.5295 - accuracy: 0.7380 - val_loss: 0.4978 - val_accuracy: 0.7054\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 0.4615 - accuracy: 0.7841 - val_loss: 0.5837 - val_accuracy: 0.7353\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 0.4775 - accuracy: 0.7732 - val_loss: 0.6021 - val_accuracy: 0.7243\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 0.4300 - accuracy: 0.8023 - val_loss: 0.4763 - val_accuracy: 0.7533\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 0.4116 - accuracy: 0.8069 - val_loss: 0.5509 - val_accuracy: 0.7529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8b1062e588>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit_generator(train_images,steps_per_epoch=EPOCH_STEPS,epochs=EPOCH,validation_data=test_images,validation_steps=TEST_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
